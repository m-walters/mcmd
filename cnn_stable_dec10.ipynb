{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%source bin/activate\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import skimage.io as io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT, IMG_WIDTH = 128, 128\n",
    "\n",
    "# labels -- [iso, D, T, X, U, L]\n",
    "NLBL = 2\n",
    "\n",
    "rundir = \"/home/walterms/project/walterms/mcmd/nn/cnn/data/edgevar/\"\n",
    "testdir = rundir+\"test/\"\n",
    "unlbldir = rundir+\"unlbl/\"\n",
    "trndir = rundir+\"train/\"\n",
    "\n",
    "testsubset = [\"edge15.tfrecords\", \"edge40.tfrecords\"]\n",
    "unlblsubset = [\"\"]\n",
    "trnsubset = [\"edge15.tfrecords\", \"edge40.tfrecords\"]\n",
    "\n",
    "testrecords, unlblrecords, trnrecords = [],[],[]\n",
    "if testsubset == [\"\"]:\n",
    "    testrecords = [testdir+x for x in os.listdir(testdir)]\n",
    "else:\n",
    "    testrecords = [testdir+x for x in testsubset]\n",
    "if trnsubset == [\"\"]:\n",
    "    trnrecords = [trndir+x for x in os.listdir(trndir)]\n",
    "else:\n",
    "    trnrecords = [trndir+x for x in trnsubset]\n",
    "if unlblsubset == [\"\"]:\n",
    "    unlblrecords = [unlbldir+x for x in os.listdir(unlbldir)]\n",
    "else:\n",
    "    unlblrecords = [unlbldir+x for x in unlblsubset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_records(filename_queue, batchSize, labeled):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    \n",
    "    features = None\n",
    "    if labeled == True:\n",
    "        features = tf.parse_single_example(\n",
    "          serialized_example,\n",
    "          # Defaults are not specified since both keys are required.\n",
    "          features={\n",
    "            'height': tf.FixedLenFeature([], tf.int64),\n",
    "            'width': tf.FixedLenFeature([], tf.int64),\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "            })\n",
    "    elif labeled == False:\n",
    "        features = tf.parse_single_example(\n",
    "          serialized_example,\n",
    "          # Defaults are not specified since both keys are required.\n",
    "          features={\n",
    "            'height': tf.FixedLenFeature([], tf.int64),\n",
    "            'width': tf.FixedLenFeature([], tf.int64),\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string)\n",
    "            })\n",
    "    else:\n",
    "        print \"Need to specify record type (labeled or not) for read_records\"\n",
    "        return\n",
    "\n",
    "    # Convert from a scalar string tensor (whose single string has\n",
    "    # length mnist.IMAGE_PIXELS) to a uint8 tensor with shape\n",
    "    # [mnist.IMAGE_PIXELS].\n",
    "    image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "#     image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "#     height = tf.cast(features['height'], tf.int32)\n",
    "#     width = tf.cast(features['width'], tf.int32)\n",
    "    \n",
    "    label = None\n",
    "    blankvec = None\n",
    "    if labeled == True:\n",
    "        label = tf.cast(features['label'], tf.int32)\n",
    "        v = [0 for i in range(NLBL)]\n",
    "        blankvec = tf.Variable(v)    \n",
    "    \n",
    "#     image_shape = tf.stack([128,128])\n",
    "    image_shape = tf.stack([IMG_HEIGHT,IMG_WIDTH])\n",
    "    image_reshaped = tf.reshape(image, image_shape)\n",
    "#     image_size_const = tf.constant((IMG_HEIGHT, IMG_WIDTH,1), dtype=tf.int32)\n",
    "    \n",
    "#     # Random transformations can be put here: right before you crop images\n",
    "#     # to predefined size. To get more information look at the stackoverflow\n",
    "#     # question linked above.\n",
    "    \n",
    "#     resized_image = tf.image.resize_image_with_crop_or_pad(image=image,\n",
    "#                                            target_height=IMG_HEIGHT,\n",
    "#                                            target_width=IMG_WIDTH)\n",
    "    \n",
    "    if labeled == True:\n",
    "        return resized_image, label, blankvec\n",
    "    else:\n",
    "        return resized_image\n",
    "\n",
    "def shuffled_queue_join(Qlist, batchSize):\n",
    "    return tf.train.shuffle_batch_join(Qlist,\n",
    "                                        batch_size=batchSize,\n",
    "                                        capacity=1000+3*batchSize,\n",
    "                                        min_after_dequeue=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'image' must have either 3 or 4 dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-832289bba0db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mtrn_queue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_input_producer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrnrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m trnQlist = [read_records(trn_queue, trnBatchSize, labeled=True) \n\u001b[0;32m---> 72\u001b[0;31m             for _ in range(len(trnrecords))]\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;31m# Even when reading in multiple threads, share the filename queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mtrnbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffled_queue_join\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrnQlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrnBatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-579ece2e8190>\u001b[0m in \u001b[0;36mread_records\u001b[0;34m(filename_queue, batchSize, labeled)\u001b[0m\n\u001b[1;32m     53\u001b[0m     resized_image = tf.image.resize_image_with_crop_or_pad(image=image,\n\u001b[1;32m     54\u001b[0m                                            \u001b[0mtarget_height\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMG_HEIGHT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                            target_width=IMG_WIDTH)\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabeled\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/walterms/jupyter_py2/lib/python2.7/site-packages/tensorflow/python/ops/image_ops_impl.pyc\u001b[0m in \u001b[0;36mresize_image_with_crop_or_pad\u001b[0;34m(image, target_height, target_width)\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mimage_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\'image\\' must have either 3 or 4 dimensions.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m   \u001b[0massert_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CheckAtLeast3DImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_static\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'image' must have either 3 or 4 dimensions."
     ]
    }
   ],
   "source": [
    "filterWidth = 15\n",
    "stride = 8\n",
    "conv1_nOut = 32\n",
    "conv2_nOut = 64\n",
    "fc1_nIn = IMG_HEIGHT*IMG_WIDTH*conv2_nOut/(stride*stride*stride*stride)\n",
    "fc1_nOut = 512\n",
    "\n",
    "trnBatchSize = 100\n",
    "testSetSize = 200\n",
    "eta = 1e-4\n",
    "nTrnIter = 2000\n",
    "testStep = nTrnIter/20\n",
    "\n",
    "beta = 1e-3\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    s = stride\n",
    "    return tf.nn.conv2d(x, W, strides=[1,s,s,1], padding='SAME')\n",
    "\n",
    "def assign_labels():\n",
    "    return\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, IMG_HEIGHT, IMG_WIDTH])\n",
    "# x = tf.placeholder(tf.float32, shape=[None, IMG_HEIGHT, IMG_WIDTH])\n",
    "x_norm = tf.scalar_mul(1./255.,x)\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, NLBL])\n",
    "\n",
    "x_image = tf.reshape(x_norm, [-1, IMG_HEIGHT, IMG_WIDTH, 1])\n",
    "\n",
    "W_conv1 = weight_variable([filterWidth, filterWidth, 1, conv1_nOut]) # [x,y,nInputChannel,nOutChannel]\n",
    "b_conv1 = bias_variable([conv1_nOut])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([filterWidth, filterWidth, conv1_nOut, conv2_nOut])\n",
    "b_conv2 = bias_variable([conv2_nOut])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2) + b_conv2)\n",
    "\n",
    "# Dividing by stride*stride for each conv layer\n",
    "W_fc1 = weight_variable([fc1_nIn, fc1_nOut])\n",
    "b_fc1 = bias_variable([fc1_nOut])\n",
    "h_conv2_flat = tf.reshape(h_conv2, [-1, fc1_nIn])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_conv2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([fc1_nOut, NLBL])\n",
    "b_fc2 = bias_variable([NLBL])\n",
    "\n",
    "y = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "regularizers = tf.nn.l2_loss(W_fc2) + tf.nn.l2_loss(W_fc1)\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "loss = tf.reduce_mean(cross_entropy + beta * regularizers)\n",
    "train_step = tf.train.AdamOptimizer(eta).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# the Qlist is needed for shuffling\n",
    "trn_queue = tf.train.string_input_producer(trnrecords)\n",
    "trnQlist = [read_records(trn_queue, trnBatchSize, labeled=True) \n",
    "            for _ in range(len(trnrecords))]\n",
    "# Even when reading in multiple threads, share the filename queue\n",
    "trnbatch = shuffled_queue_join(trnQlist, trnBatchSize)\n",
    "\n",
    "# make a Qlist for test in case we only want\n",
    "# to test a subset\n",
    "test_queue = tf.train.string_input_producer(testrecords)\n",
    "testQlist = [read_records(test_queue, testSetSize, labeled=True) \n",
    "             for _ in range(len(trnrecords))]\n",
    "testbatch = shuffled_queue_join(testQlist, testSetSize)\n",
    "\n",
    "unlbl_queue = tf.train.string_input_producer([unlblrecords[0]], num_epochs=1)\n",
    "\n",
    "# The op for initializing the variables.\n",
    "init_op = tf.group(tf.global_variables_initializer(),\n",
    "                   tf.local_variables_initializer())\n",
    "\n",
    "print \"About to start sess\"\n",
    "beg_ts = time.time()\n",
    "chkpt_ts = time.time()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init_op)\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    print \"Initialized sess\"\n",
    "    \n",
    "    for i in xrange(0,nTrnIter):\n",
    "    \n",
    "        trnbatch_py = sess.run([trnbatch[0], trnbatch[1], trnbatch[2]])\n",
    "        \n",
    "        # Assign proper labels to the lblvecs\n",
    "        # Currently lblvecs is a batch of blank (zeros) rows\n",
    "        # labels -- [iso, D, T, X, U, L]\n",
    "        for l in range(trnBatchSize):\n",
    "            trnbatch_py[2][l][trnbatch_py[1][l]] = 1\n",
    "\n",
    "        train_step.run(feed_dict={x: trnbatch_py[0], y_: trnbatch_py[2], keep_prob: 0.5})\n",
    "        \n",
    "#         print trnbatch_py[2][0:4]\n",
    "#         for p in trnbatch_py[0][0:4]:\n",
    "#             io.imshow(p)\n",
    "#             io.show()\n",
    "        now = time.time()\n",
    "        if (now-chkpt_ts) > 60:\n",
    "            print(\">> elapsed time: %f\" % (now - beg_ts))\n",
    "            chkpt_ts = now\n",
    "        if i % testStep == 0:\n",
    "            trn_accuracy = accuracy.eval(feed_dict={\n",
    "                x: trnbatch_py[0], y_: trnbatch_py[2], keep_prob: 1.0})\n",
    "\n",
    "            testbatch_py = sess.run([testbatch[0], testbatch[1], testbatch[2]])\n",
    "            testLblSums = [0 for b in range(NLBL)]\n",
    "            for l in range(testSetSize):\n",
    "                testbatch_py[2][l][testbatch_py[1][l]] = 1\n",
    "                testLblSums[testbatch_py[1][l]] += 1\n",
    "                \n",
    "            test_accuracy = accuracy.eval(feed_dict={\n",
    "                x: testbatch_py[0], y_: testbatch_py[2], keep_prob: 1.0})\n",
    "            print('step %d, training accuracy (sample) %g, test accuracy %g' \n",
    "                  % (i, trn_accuracy, test_accuracy))\n",
    "            print \"Test Label Sums:\", testLblSums\n",
    "        \n",
    "    print \"Closing sess\"\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trnbatch_py[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trnbatch_py[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    print np.min(trnbatch_py[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = 1./255*trnbatch_py[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minn = np.min(im)\n",
    "maxx = np.max(im)\n",
    "f = 1/(maxx-minn)\n",
    "im = f*(im-minn)\n",
    "print np.min(im), np.max(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imshow(im)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
