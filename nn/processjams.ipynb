{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "twopi = 2.*np.pi\n",
    "oneOver2Pi = 1./twopi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def time_usage(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        beg_ts = time.time()\n",
    "        retval = func(*args, **kwargs)\n",
    "        end_ts = time.time() \n",
    "        print(\"elapsed time: %f\" % (end_ts - beg_ts))\n",
    "        return retval\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# For the jam multiruns\n",
    "# [iso, D, T, X, U, L]\n",
    "\n",
    "mode = \"edge_3\"\n",
    "runs = {1:\"edge_3_7.00\", 0:\"edge_3_14.00\"}\n",
    "in_dir = \"/home/walterms/project/walterms/mcmd/output/scratch/\"+mode+\"/\"\n",
    "trn_dir = \"/home/walterms/project/walterms/mcmd/nn/data/train/\"\n",
    "test_dir = \"/home/walterms/project/walterms/mcmd/nn/data/test/\"\n",
    "unlabeled_dir = \"/home/walterms/project/walterms/mcmd/nn/data/unlbl/\"\n",
    "\n",
    "jidx = np.arange(2,18)\n",
    "testidxs = np.arange(0,2) # want 400 ea\n",
    "nblSkip = 1 # Skip first image\n",
    "\n",
    "# noiseLvl: sigma of Gaussian in units of rod length\n",
    "rodlen = 1.0\n",
    "noiseLvl = 0.00*rodlen\n",
    "thnoise = 0.00\n",
    "noiseappend = \"\"\n",
    "if noiseLvl > 0.0:\n",
    "    noiseappend = \"_\"+str(noiseLvl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing edge_3_14.00_2 for training data\n",
      "processing edge_3_14.00_3 for training data\n",
      "processing edge_3_14.00_4 for training data\n",
      "processing edge_3_14.00_5 for training data\n",
      "processing edge_3_14.00_6 for training data\n",
      "processing edge_3_14.00_7 for training data\n",
      "processing edge_3_14.00_8 for training data\n",
      "processing edge_3_14.00_9 for training data\n",
      "processing edge_3_14.00_10 for training data\n",
      "processing edge_3_14.00_11 for training data\n",
      "processing edge_3_14.00_12 for training data\n",
      "processing edge_3_14.00_13 for training data\n",
      "processing edge_3_14.00_14 for training data\n",
      "processing edge_3_14.00_15 for training data\n",
      "processing edge_3_14.00_16 for training data\n",
      "processing edge_3_14.00_17 for training data\n",
      "Done processing training files\n",
      "processing edge_3_7.00_2 for training data\n",
      "processing edge_3_7.00_3 for training data\n",
      "processing edge_3_7.00_4 for training data\n",
      "processing edge_3_7.00_5 for training data\n",
      "processing edge_3_7.00_6 for training data\n",
      "processing edge_3_7.00_7 for training data\n",
      "processing edge_3_7.00_8 for training data\n",
      "processing edge_3_7.00_9 for training data\n",
      "processing edge_3_7.00_10 for training data\n",
      "processing edge_3_7.00_11 for training data\n",
      "processing edge_3_7.00_12 for training data\n",
      "processing edge_3_7.00_13 for training data\n",
      "processing edge_3_7.00_14 for training data\n",
      "processing edge_3_7.00_15 for training data\n",
      "processing edge_3_7.00_16 for training data\n",
      "processing edge_3_7.00_17 for training data\n",
      "Done processing training files\n",
      "elapsed time: 95.798936\n"
     ]
    }
   ],
   "source": [
    "processTrain(noise=noiseLvl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@time_usage\n",
    "def processTrain(noise=0.):\n",
    "    for lbl in runs:\n",
    "        name = runs[lbl] \n",
    "        trnlim = -1\n",
    "        trnfnames = [name+\"_\"+str(i) for i in jidx]\n",
    "        fout = open(trn_dir+name+noiseappend,'w') #erases file\n",
    "        fout.close()\n",
    "        for f in trnfnames:\n",
    "            fin = open(in_dir+f,'r')\n",
    "            print \"processing \" + f + noiseappend + \" for training data\"\n",
    "            fout = open(trn_dir+name+noiseappend,'a')\n",
    "\n",
    "            # find width from file header\n",
    "            width, height = 0., 0.\n",
    "            l = fin.readline().split(\"|\")\n",
    "            for ll in l:\n",
    "                if \"boxEdge\" in ll:\n",
    "                    width = float(ll.split()[1])\n",
    "            height = width\n",
    "            fin.seek(0)\n",
    "\n",
    "            if width == 0.:\n",
    "                # calculate edge length based on vertices of first block\n",
    "                block = []\n",
    "                for line in fin.readlines():\n",
    "                    if line == \"\\n\": break\n",
    "                    if line[0].isalpha(): continue\n",
    "                    block.append(line)\n",
    "                fin.seek(0)\n",
    "                width, height = edgeLenCalc(block)\n",
    "\n",
    "            if not (fin.readline()[0].isalpha()): fin.seek(0)\n",
    "\n",
    "            thNorm = oneOver2Pi\n",
    "            normX, normY = 1./width, 1./height # normalize x and y\n",
    "\n",
    "            nbl = 0\n",
    "            fRot = 0. # rotation factor: 0,1,2,3. Multiplied by pi/2\n",
    "            block = []\n",
    "            for line in fin.readlines():\n",
    "                if line == \"\\n\":\n",
    "                    if nbl < nblSkip:\n",
    "                        nbl+=1\n",
    "                        block = []\n",
    "                        continue\n",
    "                    fRot = random.randint(0,3)\n",
    "                    for l in block:\n",
    "                        fout.write('%f %f %f\\n' % (l[0], l[1], l[2]))\n",
    "                    fout.write('label %f\\n\\n' % (lbl))\n",
    "                    block = []\n",
    "                    nbl+=1\n",
    "                    continue\n",
    "\n",
    "                rndxy = [0.,0.]\n",
    "                rndth = 0.\n",
    "                if noise > 0.:\n",
    "                    # Gen three random numbers\n",
    "                    rndxy = np.random.normal(0,noise,2)\n",
    "                    rndth = np.random.normal(0,twopi*thnoise,1)\n",
    "    #                 rndxy = [0.,0.]\n",
    "    #                 rndth = 0.\n",
    "\n",
    "                spt = [float(x) for x in line.split()]\n",
    "                x,y,th = spt[2],spt[3],spt[4]\n",
    "                # Rotate block\n",
    "                # note thetas should be [0,2pi] initially\n",
    "                th_ = fRot*twopi*0.25\n",
    "                th += th_ + rndth\n",
    "                if th > twopi: th-=twopi\n",
    "                th *= thNorm\n",
    "\n",
    "                x = np.cos(th_)*spt[2] - np.sin(th_)*spt[3] + rndxy[0]\n",
    "                y = np.sin(th_)*spt[2] + np.cos(th_)*spt[3] + rndxy[1]\n",
    "                # shift and normalize\n",
    "                x *= normX\n",
    "                y *= normY\n",
    "\n",
    "                block.append([x,y,th])\n",
    "\n",
    "            fout.close()\n",
    "            fin.close()\n",
    "    print \"Done processing training files\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00013795753618450133"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.random.normal(0,noiseLvl,2)\n",
    "r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing edge_3_14.00_0 for testing data\n",
      "processing edge_3_14.00_1 for testing data\n",
      "Done processing testing files\n",
      "processing edge_3_7.00_0 for testing data\n",
      "processing edge_3_7.00_1 for testing data\n",
      "Done processing testing files\n",
      "elapsed time: 11.643448\n"
     ]
    }
   ],
   "source": [
    "processTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@time_usage\n",
    "def processTest():\n",
    "    for lbl in runs:\n",
    "        name = runs[lbl]\n",
    "        testfnames = [name+\"_\"+str(i) for i in testidxs]\n",
    "        fout = open(test_dir+name,'w') #erases file\n",
    "        fout.close()\n",
    "        for f in testfnames:\n",
    "            fin = open(in_dir+f,'r')\n",
    "            print \"processing \" + f + \" for testing data\"\n",
    "            fout = open(test_dir+name,'a')\n",
    "\n",
    "            # find width from file header\n",
    "            width, height = 0., 0.\n",
    "            l = fin.readline().split(\"|\")\n",
    "            for ll in l:\n",
    "                if \"boxEdge\" in ll:\n",
    "                    width = float(ll.split()[1])\n",
    "            height = width\n",
    "            fin.seek(0)\n",
    "\n",
    "            if width == 0.:\n",
    "                # calculate edge length based on vertices of first block\n",
    "                block = []\n",
    "                for line in fin.readlines():\n",
    "                    if line == \"\\n\": break\n",
    "                    if line[0].isalpha(): continue\n",
    "                    block.append(line)\n",
    "                fin.seek(0)\n",
    "                width, height = edgeLenCalc(block)\n",
    "\n",
    "            if not (fin.readline()[0].isalpha()): fin.seek(0)\n",
    "\n",
    "            thNorm = oneOver2Pi\n",
    "            normX, normY = 1./width, 1./height # normalize x and y\n",
    "\n",
    "            nbl = 0\n",
    "            fRot = 0. # rotation factor: 0,1,2,3. Multiplied by pi/2\n",
    "            block = []\n",
    "            for line in fin.readlines():\n",
    "                if line == \"\\n\":\n",
    "                    if nbl < 1:\n",
    "                        nbl+=1\n",
    "                        block = []\n",
    "                        continue\n",
    "                    fRot = random.randint(0,3)\n",
    "                    for l in block:\n",
    "                        fout.write('%f %f %f\\n' % (l[0], l[1], l[2]))\n",
    "                    fout.write('label %f\\n\\n' % (lbl))\n",
    "                    block = []\n",
    "                    nbl+=1\n",
    "                    continue\n",
    "\n",
    "                spt = [float(x) for x in line.split()]\n",
    "                x,y,th = spt[2],spt[3],spt[4]\n",
    "                # Rotate block\n",
    "                # note thetas should be [0,2pi] initially\n",
    "                th_ = fRot*twopi*0.25\n",
    "                th += th_\n",
    "                if th > twopi: th-=twopi\n",
    "                th *= thNorm\n",
    "\n",
    "                x = np.cos(th_)*spt[2] - np.sin(th_)*spt[3]\n",
    "                y = np.sin(th_)*spt[2] + np.cos(th_)*spt[3]\n",
    "                # shift and normalize\n",
    "                x *= normX\n",
    "                y *= normY\n",
    "\n",
    "                block.append([x,y,th])\n",
    "\n",
    "            fout.close()\n",
    "            fin.close()\n",
    "    print \"Done processing testing files\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "ein = open(\"/home/walterms/mcmd/edge_3\",'r')\n",
    "for line in ein.readlines():\n",
    "    edges.append(float(line))\n",
    "unlblnames = [mode+\"_\"+\"%.2f\"%(e) for e in edges]\n",
    "uidx = np.arange(0,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing edge_3_14.00_0 for training data\n",
      "processing edge_3_14.00_1 for training data\n",
      "processing edge_3_14.00_2 for training data\n",
      "processing edge_3_14.00_3 for training data\n",
      "processing edge_3_14.00_4 for training data\n",
      "processing edge_3_14.00_5 for training data\n",
      "processing edge_3_14.00_6 for training data\n",
      "processing edge_3_14.00_7 for training data\n",
      "processing edge_3_14.00_8 for training data\n",
      "processing edge_3_14.00_9 for training data\n",
      "processing edge_3_14.00_10 for training data\n",
      "processing edge_3_14.00_11 for training data\n",
      "processing edge_3_14.00_12 for training data\n",
      "processing edge_3_14.00_13 for training data\n",
      "processing edge_3_14.00_14 for training data\n",
      "processing edge_3_14.00_15 for training data\n",
      "processing edge_3_14.00_16 for training data\n",
      "processing edge_3_14.00_17 for training data\n",
      "processing edge_3_13.59_0 for training data\n",
      "processing edge_3_13.59_1 for training data\n",
      "processing edge_3_13.59_2 for training data\n",
      "processing edge_3_13.59_3 for training data\n",
      "processing edge_3_13.59_4 for training data\n",
      "processing edge_3_13.59_5 for training data\n",
      "processing edge_3_13.59_6 for training data\n",
      "processing edge_3_13.59_7 for training data\n",
      "processing edge_3_13.59_8 for training data\n",
      "processing edge_3_13.59_9 for training data\n",
      "processing edge_3_13.59_10 for training data\n",
      "processing edge_3_13.59_11 for training data\n",
      "processing edge_3_13.59_12 for training data\n",
      "processing edge_3_13.59_13 for training data\n",
      "processing edge_3_13.59_14 for training data\n",
      "processing edge_3_13.59_15 for training data\n",
      "processing edge_3_13.59_16 for training data\n",
      "processing edge_3_13.59_17 for training data\n",
      "processing edge_3_13.22_0 for training data\n",
      "processing edge_3_13.22_1 for training data\n",
      "processing edge_3_13.22_2 for training data\n",
      "processing edge_3_13.22_3 for training data\n",
      "processing edge_3_13.22_4 for training data\n",
      "processing edge_3_13.22_5 for training data\n",
      "processing edge_3_13.22_6 for training data\n",
      "processing edge_3_13.22_7 for training data\n",
      "processing edge_3_13.22_8 for training data\n",
      "processing edge_3_13.22_9 for training data\n",
      "processing edge_3_13.22_10 for training data\n",
      "processing edge_3_13.22_11 for training data\n",
      "processing edge_3_13.22_12 for training data\n",
      "processing edge_3_13.22_13 for training data\n",
      "processing edge_3_13.22_14 for training data\n",
      "processing edge_3_13.22_15 for training data\n",
      "processing edge_3_13.22_16 for training data\n",
      "processing edge_3_13.22_17 for training data\n",
      "processing edge_3_12.87_0 for training data\n",
      "processing edge_3_12.87_1 for training data\n",
      "processing edge_3_12.87_2 for training data\n",
      "processing edge_3_12.87_3 for training data\n",
      "processing edge_3_12.87_4 for training data\n",
      "processing edge_3_12.87_5 for training data\n",
      "processing edge_3_12.87_6 for training data\n",
      "processing edge_3_12.87_7 for training data\n",
      "processing edge_3_12.87_8 for training data\n",
      "processing edge_3_12.87_9 for training data\n",
      "processing edge_3_12.87_10 for training data\n",
      "processing edge_3_12.87_11 for training data\n",
      "processing edge_3_12.87_12 for training data\n",
      "processing edge_3_12.87_13 for training data\n",
      "processing edge_3_12.87_14 for training data\n",
      "processing edge_3_12.87_15 for training data\n",
      "processing edge_3_12.87_16 for training data\n",
      "processing edge_3_12.87_17 for training data\n",
      "processing edge_3_12.55_0 for training data\n",
      "processing edge_3_12.55_1 for training data\n",
      "processing edge_3_12.55_2 for training data\n",
      "processing edge_3_12.55_3 for training data\n",
      "processing edge_3_12.55_4 for training data\n",
      "processing edge_3_12.55_5 for training data\n",
      "processing edge_3_12.55_6 for training data\n",
      "processing edge_3_12.55_7 for training data\n",
      "processing edge_3_12.55_8 for training data\n",
      "processing edge_3_12.55_9 for training data\n",
      "processing edge_3_12.55_10 for training data\n",
      "processing edge_3_12.55_11 for training data\n",
      "processing edge_3_12.55_12 for training data\n",
      "processing edge_3_12.55_13 for training data\n",
      "processing edge_3_12.55_14 for training data\n",
      "processing edge_3_12.55_15 for training data\n",
      "processing edge_3_12.55_16 for training data\n",
      "processing edge_3_12.55_17 for training data\n",
      "processing edge_3_12.25_0 for training data\n",
      "processing edge_3_12.25_1 for training data\n",
      "processing edge_3_12.25_2 for training data\n",
      "processing edge_3_12.25_3 for training data\n",
      "processing edge_3_12.25_4 for training data\n",
      "processing edge_3_12.25_5 for training data\n",
      "processing edge_3_12.25_6 for training data\n",
      "processing edge_3_12.25_7 for training data\n",
      "processing edge_3_12.25_8 for training data\n",
      "processing edge_3_12.25_9 for training data\n",
      "processing edge_3_12.25_10 for training data\n",
      "processing edge_3_12.25_11 for training data\n",
      "processing edge_3_12.25_12 for training data\n",
      "processing edge_3_12.25_13 for training data\n",
      "processing edge_3_12.25_14 for training data\n",
      "processing edge_3_12.25_15 for training data\n",
      "processing edge_3_12.25_16 for training data\n",
      "processing edge_3_12.25_17 for training data\n",
      "processing edge_3_11.97_0 for training data\n",
      "processing edge_3_11.97_1 for training data\n",
      "processing edge_3_11.97_2 for training data\n",
      "processing edge_3_11.97_3 for training data\n",
      "processing edge_3_11.97_4 for training data\n",
      "processing edge_3_11.97_5 for training data\n",
      "processing edge_3_11.97_6 for training data\n",
      "processing edge_3_11.97_7 for training data\n",
      "processing edge_3_11.97_8 for training data\n",
      "processing edge_3_11.97_9 for training data\n",
      "processing edge_3_11.97_10 for training data\n",
      "processing edge_3_11.97_11 for training data\n",
      "processing edge_3_11.97_12 for training data\n",
      "processing edge_3_11.97_13 for training data\n",
      "processing edge_3_11.97_14 for training data\n",
      "processing edge_3_11.97_15 for training data\n",
      "processing edge_3_11.97_16 for training data\n",
      "processing edge_3_11.97_17 for training data\n",
      "processing edge_3_11.71_0 for training data\n",
      "processing edge_3_11.71_1 for training data\n",
      "processing edge_3_11.71_2 for training data\n",
      "processing edge_3_11.71_3 for training data\n",
      "processing edge_3_11.71_4 for training data\n",
      "processing edge_3_11.71_5 for training data\n",
      "processing edge_3_11.71_6 for training data\n",
      "processing edge_3_11.71_7 for training data\n",
      "processing edge_3_11.71_8 for training data\n",
      "processing edge_3_11.71_9 for training data\n",
      "processing edge_3_11.71_10 for training data\n",
      "processing edge_3_11.71_11 for training data\n",
      "processing edge_3_11.71_12 for training data\n",
      "processing edge_3_11.71_13 for training data\n",
      "processing edge_3_11.71_14 for training data\n",
      "processing edge_3_11.71_15 for training data\n",
      "processing edge_3_11.71_16 for training data\n",
      "processing edge_3_11.71_17 for training data\n",
      "processing edge_3_11.47_0 for training data\n",
      "processing edge_3_11.47_1 for training data\n",
      "processing edge_3_11.47_2 for training data\n",
      "processing edge_3_11.47_3 for training data\n",
      "processing edge_3_11.47_4 for training data\n",
      "processing edge_3_11.47_5 for training data\n",
      "processing edge_3_11.47_6 for training data\n",
      "processing edge_3_11.47_7 for training data\n",
      "processing edge_3_11.47_8 for training data\n",
      "processing edge_3_11.47_9 for training data\n",
      "processing edge_3_11.47_10 for training data\n",
      "processing edge_3_11.47_11 for training data\n",
      "processing edge_3_11.47_12 for training data\n",
      "processing edge_3_11.47_13 for training data\n",
      "processing edge_3_11.47_14 for training data\n",
      "processing edge_3_11.47_15 for training data\n",
      "processing edge_3_11.47_16 for training data\n",
      "processing edge_3_11.47_17 for training data\n",
      "processing edge_3_11.24_0 for training data\n",
      "processing edge_3_11.24_1 for training data\n",
      "processing edge_3_11.24_2 for training data\n",
      "processing edge_3_11.24_3 for training data\n",
      "processing edge_3_11.24_4 for training data\n",
      "processing edge_3_11.24_5 for training data\n",
      "processing edge_3_11.24_6 for training data\n",
      "processing edge_3_11.24_7 for training data\n",
      "processing edge_3_11.24_8 for training data\n",
      "processing edge_3_11.24_9 for training data\n",
      "processing edge_3_11.24_10 for training data\n",
      "processing edge_3_11.24_11 for training data\n",
      "processing edge_3_11.24_12 for training data\n",
      "processing edge_3_11.24_13 for training data\n",
      "processing edge_3_11.24_14 for training data\n",
      "processing edge_3_11.24_15 for training data\n",
      "processing edge_3_11.24_16 for training data\n",
      "processing edge_3_11.24_17 for training data\n",
      "processing edge_3_11.03_0 for training data\n",
      "processing edge_3_11.03_1 for training data\n",
      "processing edge_3_11.03_2 for training data\n",
      "processing edge_3_11.03_3 for training data\n",
      "processing edge_3_11.03_4 for training data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing edge_3_11.03_5 for training data\n",
      "processing edge_3_11.03_6 for training data\n",
      "processing edge_3_11.03_7 for training data\n",
      "processing edge_3_11.03_8 for training data\n",
      "processing edge_3_11.03_9 for training data\n",
      "processing edge_3_11.03_10 for training data\n",
      "processing edge_3_11.03_11 for training data\n",
      "processing edge_3_11.03_12 for training data\n",
      "processing edge_3_11.03_13 for training data\n",
      "processing edge_3_11.03_14 for training data\n",
      "processing edge_3_11.03_15 for training data\n",
      "processing edge_3_11.03_16 for training data\n",
      "processing edge_3_11.03_17 for training data\n",
      "processing edge_3_10.82_0 for training data\n",
      "processing edge_3_10.82_1 for training data\n",
      "processing edge_3_10.82_2 for training data\n",
      "processing edge_3_10.82_3 for training data\n",
      "processing edge_3_10.82_4 for training data\n",
      "processing edge_3_10.82_5 for training data\n",
      "processing edge_3_10.82_6 for training data\n",
      "processing edge_3_10.82_7 for training data\n",
      "processing edge_3_10.82_8 for training data\n",
      "processing edge_3_10.82_9 for training data\n",
      "processing edge_3_10.82_10 for training data\n",
      "processing edge_3_10.82_11 for training data\n",
      "processing edge_3_10.82_12 for training data\n",
      "processing edge_3_10.82_13 for training data\n",
      "processing edge_3_10.82_14 for training data\n",
      "processing edge_3_10.82_15 for training data\n",
      "processing edge_3_10.82_16 for training data\n",
      "processing edge_3_10.82_17 for training data\n",
      "processing edge_3_10.63_0 for training data\n",
      "processing edge_3_10.63_1 for training data\n",
      "processing edge_3_10.63_2 for training data\n",
      "processing edge_3_10.63_3 for training data\n",
      "processing edge_3_10.63_4 for training data\n",
      "processing edge_3_10.63_5 for training data\n",
      "processing edge_3_10.63_6 for training data\n",
      "processing edge_3_10.63_7 for training data\n",
      "processing edge_3_10.63_8 for training data\n",
      "processing edge_3_10.63_9 for training data\n",
      "processing edge_3_10.63_10 for training data\n",
      "processing edge_3_10.63_11 for training data\n",
      "processing edge_3_10.63_12 for training data\n",
      "processing edge_3_10.63_13 for training data\n",
      "processing edge_3_10.63_14 for training data\n",
      "processing edge_3_10.63_15 for training data\n",
      "processing edge_3_10.63_16 for training data\n",
      "processing edge_3_10.63_17 for training data\n",
      "processing edge_3_10.45_0 for training data\n",
      "processing edge_3_10.45_1 for training data\n",
      "processing edge_3_10.45_2 for training data\n",
      "processing edge_3_10.45_3 for training data\n",
      "processing edge_3_10.45_4 for training data\n",
      "processing edge_3_10.45_5 for training data\n",
      "processing edge_3_10.45_6 for training data\n",
      "processing edge_3_10.45_7 for training data\n",
      "processing edge_3_10.45_8 for training data\n",
      "processing edge_3_10.45_9 for training data\n",
      "processing edge_3_10.45_10 for training data\n",
      "processing edge_3_10.45_11 for training data\n",
      "processing edge_3_10.45_12 for training data\n",
      "processing edge_3_10.45_13 for training data\n",
      "processing edge_3_10.45_14 for training data\n",
      "processing edge_3_10.45_15 for training data\n",
      "processing edge_3_10.45_16 for training data\n",
      "processing edge_3_10.45_17 for training data\n",
      "processing edge_3_10.27_0 for training data\n",
      "processing edge_3_10.27_1 for training data\n",
      "processing edge_3_10.27_2 for training data\n",
      "processing edge_3_10.27_3 for training data\n",
      "processing edge_3_10.27_4 for training data\n",
      "processing edge_3_10.27_5 for training data\n",
      "processing edge_3_10.27_6 for training data\n",
      "processing edge_3_10.27_7 for training data\n",
      "processing edge_3_10.27_8 for training data\n",
      "processing edge_3_10.27_9 for training data\n",
      "processing edge_3_10.27_10 for training data\n",
      "processing edge_3_10.27_11 for training data\n",
      "processing edge_3_10.27_12 for training data\n",
      "processing edge_3_10.27_13 for training data\n",
      "processing edge_3_10.27_14 for training data\n",
      "processing edge_3_10.27_15 for training data\n",
      "processing edge_3_10.27_16 for training data\n",
      "processing edge_3_10.27_17 for training data\n",
      "processing edge_3_10.11_0 for training data\n",
      "processing edge_3_10.11_1 for training data\n",
      "processing edge_3_10.11_2 for training data\n",
      "processing edge_3_10.11_3 for training data\n",
      "processing edge_3_10.11_4 for training data\n",
      "processing edge_3_10.11_5 for training data\n",
      "processing edge_3_10.11_6 for training data\n",
      "processing edge_3_10.11_7 for training data\n",
      "processing edge_3_10.11_8 for training data\n",
      "processing edge_3_10.11_9 for training data\n",
      "processing edge_3_10.11_10 for training data\n",
      "processing edge_3_10.11_11 for training data\n",
      "processing edge_3_10.11_12 for training data\n",
      "processing edge_3_10.11_13 for training data\n",
      "processing edge_3_10.11_14 for training data\n",
      "processing edge_3_10.11_15 for training data\n",
      "processing edge_3_10.11_16 for training data\n",
      "processing edge_3_10.11_17 for training data\n",
      "processing edge_3_9.95_0 for training data\n",
      "processing edge_3_9.95_1 for training data\n",
      "processing edge_3_9.95_2 for training data\n",
      "processing edge_3_9.95_3 for training data\n",
      "processing edge_3_9.95_4 for training data\n",
      "processing edge_3_9.95_5 for training data\n",
      "processing edge_3_9.95_6 for training data\n",
      "processing edge_3_9.95_7 for training data\n",
      "processing edge_3_9.95_8 for training data\n",
      "processing edge_3_9.95_9 for training data\n",
      "processing edge_3_9.95_10 for training data\n",
      "processing edge_3_9.95_11 for training data\n",
      "processing edge_3_9.95_12 for training data\n",
      "processing edge_3_9.95_13 for training data\n",
      "processing edge_3_9.95_14 for training data\n",
      "processing edge_3_9.95_15 for training data\n",
      "processing edge_3_9.95_16 for training data\n",
      "processing edge_3_9.95_17 for training data\n",
      "processing edge_3_9.80_0 for training data\n",
      "processing edge_3_9.80_1 for training data\n",
      "processing edge_3_9.80_2 for training data\n",
      "processing edge_3_9.80_3 for training data\n",
      "processing edge_3_9.80_4 for training data\n",
      "processing edge_3_9.80_5 for training data\n",
      "processing edge_3_9.80_6 for training data\n",
      "processing edge_3_9.80_7 for training data\n",
      "processing edge_3_9.80_8 for training data\n",
      "processing edge_3_9.80_9 for training data\n",
      "processing edge_3_9.80_10 for training data\n",
      "processing edge_3_9.80_11 for training data\n",
      "processing edge_3_9.80_12 for training data\n",
      "processing edge_3_9.80_13 for training data\n",
      "processing edge_3_9.80_14 for training data\n",
      "processing edge_3_9.80_15 for training data\n",
      "processing edge_3_9.80_16 for training data\n",
      "processing edge_3_9.80_17 for training data\n",
      "processing edge_3_9.66_0 for training data\n",
      "processing edge_3_9.66_1 for training data\n",
      "processing edge_3_9.66_2 for training data\n",
      "processing edge_3_9.66_3 for training data\n",
      "processing edge_3_9.66_4 for training data\n",
      "processing edge_3_9.66_5 for training data\n",
      "processing edge_3_9.66_6 for training data\n",
      "processing edge_3_9.66_7 for training data\n",
      "processing edge_3_9.66_8 for training data\n",
      "processing edge_3_9.66_9 for training data\n",
      "processing edge_3_9.66_10 for training data\n",
      "processing edge_3_9.66_11 for training data\n",
      "processing edge_3_9.66_12 for training data\n",
      "processing edge_3_9.66_13 for training data\n",
      "processing edge_3_9.66_14 for training data\n",
      "processing edge_3_9.66_15 for training data\n",
      "processing edge_3_9.66_16 for training data\n",
      "processing edge_3_9.66_17 for training data\n",
      "processing edge_3_9.52_0 for training data\n",
      "processing edge_3_9.52_1 for training data\n",
      "processing edge_3_9.52_2 for training data\n",
      "processing edge_3_9.52_3 for training data\n",
      "processing edge_3_9.52_4 for training data\n",
      "processing edge_3_9.52_5 for training data\n",
      "processing edge_3_9.52_6 for training data\n",
      "processing edge_3_9.52_7 for training data\n",
      "processing edge_3_9.52_8 for training data\n",
      "processing edge_3_9.52_9 for training data\n",
      "processing edge_3_9.52_10 for training data\n",
      "processing edge_3_9.52_11 for training data\n",
      "processing edge_3_9.52_12 for training data\n",
      "processing edge_3_9.52_13 for training data\n",
      "processing edge_3_9.52_14 for training data\n",
      "processing edge_3_9.52_15 for training data\n",
      "processing edge_3_9.52_16 for training data\n",
      "processing edge_3_9.52_17 for training data\n",
      "processing edge_3_9.38_0 for training data\n",
      "processing edge_3_9.38_1 for training data\n",
      "processing edge_3_9.38_2 for training data\n",
      "processing edge_3_9.38_3 for training data\n",
      "processing edge_3_9.38_4 for training data\n",
      "processing edge_3_9.38_5 for training data\n",
      "processing edge_3_9.38_6 for training data\n",
      "processing edge_3_9.38_7 for training data\n",
      "processing edge_3_9.38_8 for training data\n",
      "processing edge_3_9.38_9 for training data\n",
      "processing edge_3_9.38_10 for training data\n",
      "processing edge_3_9.38_11 for training data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing edge_3_9.38_12 for training data\n",
      "processing edge_3_9.38_13 for training data\n",
      "processing edge_3_9.38_14 for training data\n",
      "processing edge_3_9.38_15 for training data\n",
      "processing edge_3_9.38_16 for training data\n",
      "processing edge_3_9.38_17 for training data\n",
      "processing edge_3_9.26_0 for training data\n",
      "processing edge_3_9.26_1 for training data\n",
      "processing edge_3_9.26_2 for training data\n",
      "processing edge_3_9.26_3 for training data\n",
      "processing edge_3_9.26_4 for training data\n",
      "processing edge_3_9.26_5 for training data\n",
      "processing edge_3_9.26_6 for training data\n",
      "processing edge_3_9.26_7 for training data\n",
      "processing edge_3_9.26_8 for training data\n",
      "processing edge_3_9.26_9 for training data\n",
      "processing edge_3_9.26_10 for training data\n",
      "processing edge_3_9.26_11 for training data\n",
      "processing edge_3_9.26_12 for training data\n",
      "processing edge_3_9.26_13 for training data\n",
      "processing edge_3_9.26_14 for training data\n",
      "processing edge_3_9.26_15 for training data\n",
      "processing edge_3_9.26_16 for training data\n",
      "processing edge_3_9.26_17 for training data\n",
      "processing edge_3_9.14_0 for training data\n",
      "processing edge_3_9.14_1 for training data\n",
      "processing edge_3_9.14_2 for training data\n",
      "processing edge_3_9.14_3 for training data\n",
      "processing edge_3_9.14_4 for training data\n",
      "processing edge_3_9.14_5 for training data\n",
      "processing edge_3_9.14_6 for training data\n",
      "processing edge_3_9.14_7 for training data\n",
      "processing edge_3_9.14_8 for training data\n",
      "processing edge_3_9.14_9 for training data\n",
      "processing edge_3_9.14_10 for training data\n",
      "processing edge_3_9.14_11 for training data\n",
      "processing edge_3_9.14_12 for training data\n",
      "processing edge_3_9.14_13 for training data\n",
      "processing edge_3_9.14_14 for training data\n",
      "processing edge_3_9.14_15 for training data\n",
      "processing edge_3_9.14_16 for training data\n",
      "processing edge_3_9.14_17 for training data\n",
      "processing edge_3_9.02_0 for training data\n",
      "processing edge_3_9.02_1 for training data\n",
      "processing edge_3_9.02_2 for training data\n",
      "processing edge_3_9.02_3 for training data\n",
      "processing edge_3_9.02_4 for training data\n",
      "processing edge_3_9.02_5 for training data\n",
      "processing edge_3_9.02_6 for training data\n",
      "processing edge_3_9.02_7 for training data\n",
      "processing edge_3_9.02_8 for training data\n",
      "processing edge_3_9.02_9 for training data\n",
      "processing edge_3_9.02_10 for training data\n",
      "processing edge_3_9.02_11 for training data\n",
      "processing edge_3_9.02_12 for training data\n",
      "processing edge_3_9.02_13 for training data\n",
      "processing edge_3_9.02_14 for training data\n",
      "processing edge_3_9.02_15 for training data\n",
      "processing edge_3_9.02_16 for training data\n",
      "processing edge_3_9.02_17 for training data\n",
      "processing edge_3_8.91_0 for training data\n",
      "processing edge_3_8.91_1 for training data\n",
      "processing edge_3_8.91_2 for training data\n",
      "processing edge_3_8.91_3 for training data\n",
      "processing edge_3_8.91_4 for training data\n",
      "processing edge_3_8.91_5 for training data\n",
      "processing edge_3_8.91_6 for training data\n",
      "processing edge_3_8.91_7 for training data\n",
      "processing edge_3_8.91_8 for training data\n",
      "processing edge_3_8.91_9 for training data\n",
      "processing edge_3_8.91_10 for training data\n",
      "processing edge_3_8.91_11 for training data\n",
      "processing edge_3_8.91_12 for training data\n",
      "processing edge_3_8.91_13 for training data\n",
      "processing edge_3_8.91_14 for training data\n",
      "processing edge_3_8.91_15 for training data\n",
      "processing edge_3_8.91_16 for training data\n",
      "processing edge_3_8.91_17 for training data\n",
      "processing edge_3_8.80_0 for training data\n",
      "processing edge_3_8.80_1 for training data\n",
      "processing edge_3_8.80_2 for training data\n",
      "processing edge_3_8.80_3 for training data\n",
      "processing edge_3_8.80_4 for training data\n",
      "processing edge_3_8.80_5 for training data\n",
      "processing edge_3_8.80_6 for training data\n",
      "processing edge_3_8.80_7 for training data\n",
      "processing edge_3_8.80_8 for training data\n",
      "processing edge_3_8.80_9 for training data\n",
      "processing edge_3_8.80_10 for training data\n",
      "processing edge_3_8.80_11 for training data\n",
      "processing edge_3_8.80_12 for training data\n",
      "processing edge_3_8.80_13 for training data\n",
      "processing edge_3_8.80_14 for training data\n",
      "processing edge_3_8.80_15 for training data\n",
      "processing edge_3_8.80_16 for training data\n",
      "processing edge_3_8.80_17 for training data\n",
      "processing edge_3_8.69_0 for training data\n",
      "processing edge_3_8.69_1 for training data\n",
      "processing edge_3_8.69_2 for training data\n",
      "processing edge_3_8.69_3 for training data\n",
      "processing edge_3_8.69_4 for training data\n",
      "processing edge_3_8.69_5 for training data\n",
      "processing edge_3_8.69_6 for training data\n",
      "processing edge_3_8.69_7 for training data\n",
      "processing edge_3_8.69_8 for training data\n",
      "processing edge_3_8.69_9 for training data\n",
      "processing edge_3_8.69_10 for training data\n",
      "processing edge_3_8.69_11 for training data\n",
      "processing edge_3_8.69_12 for training data\n",
      "processing edge_3_8.69_13 for training data\n",
      "processing edge_3_8.69_14 for training data\n",
      "processing edge_3_8.69_15 for training data\n",
      "processing edge_3_8.69_16 for training data\n",
      "processing edge_3_8.69_17 for training data\n",
      "processing edge_3_8.60_0 for training data\n",
      "processing edge_3_8.60_1 for training data\n",
      "processing edge_3_8.60_2 for training data\n",
      "processing edge_3_8.60_3 for training data\n",
      "processing edge_3_8.60_4 for training data\n",
      "processing edge_3_8.60_5 for training data\n",
      "processing edge_3_8.60_6 for training data\n",
      "processing edge_3_8.60_7 for training data\n",
      "processing edge_3_8.60_8 for training data\n",
      "processing edge_3_8.60_9 for training data\n",
      "processing edge_3_8.60_10 for training data\n",
      "processing edge_3_8.60_11 for training data\n",
      "processing edge_3_8.60_12 for training data\n",
      "processing edge_3_8.60_13 for training data\n",
      "processing edge_3_8.60_14 for training data\n",
      "processing edge_3_8.60_15 for training data\n",
      "processing edge_3_8.60_16 for training data\n",
      "processing edge_3_8.60_17 for training data\n",
      "processing edge_3_8.50_0 for training data\n",
      "processing edge_3_8.50_1 for training data\n",
      "processing edge_3_8.50_2 for training data\n",
      "processing edge_3_8.50_3 for training data\n",
      "processing edge_3_8.50_4 for training data\n",
      "processing edge_3_8.50_5 for training data\n",
      "processing edge_3_8.50_6 for training data\n",
      "processing edge_3_8.50_7 for training data\n",
      "processing edge_3_8.50_8 for training data\n",
      "processing edge_3_8.50_9 for training data\n",
      "processing edge_3_8.50_10 for training data\n",
      "processing edge_3_8.50_11 for training data\n",
      "processing edge_3_8.50_12 for training data\n",
      "processing edge_3_8.50_13 for training data\n",
      "processing edge_3_8.50_14 for training data\n",
      "processing edge_3_8.50_15 for training data\n",
      "processing edge_3_8.50_16 for training data\n",
      "processing edge_3_8.50_17 for training data\n",
      "processing edge_3_8.40_0 for training data\n",
      "processing edge_3_8.40_1 for training data\n",
      "processing edge_3_8.40_2 for training data\n",
      "processing edge_3_8.40_3 for training data\n",
      "processing edge_3_8.40_4 for training data\n",
      "processing edge_3_8.40_5 for training data\n",
      "processing edge_3_8.40_6 for training data\n",
      "processing edge_3_8.40_7 for training data\n",
      "processing edge_3_8.40_8 for training data\n",
      "processing edge_3_8.40_9 for training data\n",
      "processing edge_3_8.40_10 for training data\n",
      "processing edge_3_8.40_11 for training data\n",
      "processing edge_3_8.40_12 for training data\n",
      "processing edge_3_8.40_13 for training data\n",
      "processing edge_3_8.40_14 for training data\n",
      "processing edge_3_8.40_15 for training data\n",
      "processing edge_3_8.40_16 for training data\n",
      "processing edge_3_8.40_17 for training data\n",
      "processing edge_3_8.31_0 for training data\n",
      "processing edge_3_8.31_1 for training data\n",
      "processing edge_3_8.31_2 for training data\n",
      "processing edge_3_8.31_3 for training data\n",
      "processing edge_3_8.31_4 for training data\n",
      "processing edge_3_8.31_5 for training data\n",
      "processing edge_3_8.31_6 for training data\n",
      "processing edge_3_8.31_7 for training data\n",
      "processing edge_3_8.31_8 for training data\n",
      "processing edge_3_8.31_9 for training data\n",
      "processing edge_3_8.31_10 for training data\n",
      "processing edge_3_8.31_11 for training data\n",
      "processing edge_3_8.31_12 for training data\n",
      "processing edge_3_8.31_13 for training data\n",
      "processing edge_3_8.31_14 for training data\n",
      "processing edge_3_8.31_15 for training data\n",
      "processing edge_3_8.31_16 for training data\n",
      "processing edge_3_8.31_17 for training data\n",
      "processing edge_3_8.22_0 for training data\n",
      "processing edge_3_8.22_1 for training data\n",
      "processing edge_3_8.22_2 for training data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing edge_3_8.22_3 for training data\n",
      "processing edge_3_8.22_4 for training data\n",
      "processing edge_3_8.22_5 for training data\n",
      "processing edge_3_8.22_6 for training data\n",
      "processing edge_3_8.22_7 for training data\n",
      "processing edge_3_8.22_8 for training data\n",
      "processing edge_3_8.22_9 for training data\n",
      "processing edge_3_8.22_10 for training data\n",
      "processing edge_3_8.22_11 for training data\n",
      "processing edge_3_8.22_12 for training data\n",
      "processing edge_3_8.22_13 for training data\n",
      "processing edge_3_8.22_14 for training data\n",
      "processing edge_3_8.22_15 for training data\n",
      "processing edge_3_8.22_16 for training data\n",
      "processing edge_3_8.22_17 for training data\n",
      "processing edge_3_8.14_0 for training data\n",
      "processing edge_3_8.14_1 for training data\n",
      "processing edge_3_8.14_2 for training data\n",
      "processing edge_3_8.14_3 for training data\n",
      "processing edge_3_8.14_4 for training data\n",
      "processing edge_3_8.14_5 for training data\n",
      "processing edge_3_8.14_6 for training data\n",
      "processing edge_3_8.14_7 for training data\n",
      "processing edge_3_8.14_8 for training data\n",
      "processing edge_3_8.14_9 for training data\n",
      "processing edge_3_8.14_10 for training data\n",
      "processing edge_3_8.14_11 for training data\n",
      "processing edge_3_8.14_12 for training data\n",
      "processing edge_3_8.14_13 for training data\n",
      "processing edge_3_8.14_14 for training data\n",
      "processing edge_3_8.14_15 for training data\n",
      "processing edge_3_8.14_16 for training data\n",
      "processing edge_3_8.14_17 for training data\n",
      "processing edge_3_8.05_0 for training data\n",
      "processing edge_3_8.05_1 for training data\n",
      "processing edge_3_8.05_2 for training data\n",
      "processing edge_3_8.05_3 for training data\n",
      "processing edge_3_8.05_4 for training data\n",
      "processing edge_3_8.05_5 for training data\n",
      "processing edge_3_8.05_6 for training data\n",
      "processing edge_3_8.05_7 for training data\n",
      "processing edge_3_8.05_8 for training data\n",
      "processing edge_3_8.05_9 for training data\n",
      "processing edge_3_8.05_10 for training data\n",
      "processing edge_3_8.05_11 for training data\n",
      "processing edge_3_8.05_12 for training data\n",
      "processing edge_3_8.05_13 for training data\n",
      "processing edge_3_8.05_14 for training data\n",
      "processing edge_3_8.05_15 for training data\n",
      "processing edge_3_8.05_16 for training data\n",
      "processing edge_3_8.05_17 for training data\n",
      "processing edge_3_7.98_0 for training data\n",
      "processing edge_3_7.98_1 for training data\n",
      "processing edge_3_7.98_2 for training data\n",
      "processing edge_3_7.98_3 for training data\n",
      "processing edge_3_7.98_4 for training data\n",
      "processing edge_3_7.98_5 for training data\n",
      "processing edge_3_7.98_6 for training data\n",
      "processing edge_3_7.98_7 for training data\n",
      "processing edge_3_7.98_8 for training data\n",
      "processing edge_3_7.98_9 for training data\n",
      "processing edge_3_7.98_10 for training data\n",
      "processing edge_3_7.98_11 for training data\n",
      "processing edge_3_7.98_12 for training data\n",
      "processing edge_3_7.98_13 for training data\n",
      "processing edge_3_7.98_14 for training data\n",
      "processing edge_3_7.98_15 for training data\n",
      "processing edge_3_7.98_16 for training data\n",
      "processing edge_3_7.98_17 for training data\n",
      "processing edge_3_7.90_0 for training data\n",
      "processing edge_3_7.90_1 for training data\n",
      "processing edge_3_7.90_2 for training data\n",
      "processing edge_3_7.90_3 for training data\n",
      "processing edge_3_7.90_4 for training data\n",
      "processing edge_3_7.90_5 for training data\n",
      "processing edge_3_7.90_6 for training data\n",
      "processing edge_3_7.90_7 for training data\n",
      "processing edge_3_7.90_8 for training data\n",
      "processing edge_3_7.90_9 for training data\n",
      "processing edge_3_7.90_10 for training data\n",
      "processing edge_3_7.90_11 for training data\n",
      "processing edge_3_7.90_12 for training data\n",
      "processing edge_3_7.90_13 for training data\n",
      "processing edge_3_7.90_14 for training data\n",
      "processing edge_3_7.90_15 for training data\n",
      "processing edge_3_7.90_16 for training data\n",
      "processing edge_3_7.90_17 for training data\n",
      "processing edge_3_7.82_0 for training data\n",
      "processing edge_3_7.82_1 for training data\n",
      "processing edge_3_7.82_2 for training data\n",
      "processing edge_3_7.82_3 for training data\n",
      "processing edge_3_7.82_4 for training data\n",
      "processing edge_3_7.82_5 for training data\n",
      "processing edge_3_7.82_6 for training data\n",
      "processing edge_3_7.82_7 for training data\n",
      "processing edge_3_7.82_8 for training data\n",
      "processing edge_3_7.82_9 for training data\n",
      "processing edge_3_7.82_10 for training data\n",
      "processing edge_3_7.82_11 for training data\n",
      "processing edge_3_7.82_12 for training data\n",
      "processing edge_3_7.82_13 for training data\n",
      "processing edge_3_7.82_14 for training data\n",
      "processing edge_3_7.82_15 for training data\n",
      "processing edge_3_7.82_16 for training data\n",
      "processing edge_3_7.82_17 for training data\n",
      "processing edge_3_7.75_0 for training data\n",
      "processing edge_3_7.75_1 for training data\n",
      "processing edge_3_7.75_2 for training data\n",
      "processing edge_3_7.75_3 for training data\n",
      "processing edge_3_7.75_4 for training data\n",
      "processing edge_3_7.75_5 for training data\n",
      "processing edge_3_7.75_6 for training data\n",
      "processing edge_3_7.75_7 for training data\n",
      "processing edge_3_7.75_8 for training data\n",
      "processing edge_3_7.75_9 for training data\n",
      "processing edge_3_7.75_10 for training data\n",
      "processing edge_3_7.75_11 for training data\n",
      "processing edge_3_7.75_12 for training data\n",
      "processing edge_3_7.75_13 for training data\n",
      "processing edge_3_7.75_14 for training data\n",
      "processing edge_3_7.75_15 for training data\n",
      "processing edge_3_7.75_16 for training data\n",
      "processing edge_3_7.75_17 for training data\n",
      "processing edge_3_7.68_0 for training data\n",
      "processing edge_3_7.68_1 for training data\n",
      "processing edge_3_7.68_2 for training data\n",
      "processing edge_3_7.68_3 for training data\n",
      "processing edge_3_7.68_4 for training data\n",
      "processing edge_3_7.68_5 for training data\n",
      "processing edge_3_7.68_6 for training data\n",
      "processing edge_3_7.68_7 for training data\n",
      "processing edge_3_7.68_8 for training data\n",
      "processing edge_3_7.68_9 for training data\n",
      "processing edge_3_7.68_10 for training data\n",
      "processing edge_3_7.68_11 for training data\n",
      "processing edge_3_7.68_12 for training data\n",
      "processing edge_3_7.68_13 for training data\n",
      "processing edge_3_7.68_14 for training data\n",
      "processing edge_3_7.68_15 for training data\n",
      "processing edge_3_7.68_16 for training data\n",
      "processing edge_3_7.68_17 for training data\n",
      "processing edge_3_7.61_0 for training data\n",
      "processing edge_3_7.61_1 for training data\n",
      "processing edge_3_7.61_2 for training data\n",
      "processing edge_3_7.61_3 for training data\n",
      "processing edge_3_7.61_4 for training data\n",
      "processing edge_3_7.61_5 for training data\n",
      "processing edge_3_7.61_6 for training data\n",
      "processing edge_3_7.61_7 for training data\n",
      "processing edge_3_7.61_8 for training data\n",
      "processing edge_3_7.61_9 for training data\n",
      "processing edge_3_7.61_10 for training data\n",
      "processing edge_3_7.61_11 for training data\n",
      "processing edge_3_7.61_12 for training data\n",
      "processing edge_3_7.61_13 for training data\n",
      "processing edge_3_7.61_14 for training data\n",
      "processing edge_3_7.61_15 for training data\n",
      "processing edge_3_7.61_16 for training data\n",
      "processing edge_3_7.61_17 for training data\n",
      "processing edge_3_7.54_0 for training data\n",
      "processing edge_3_7.54_1 for training data\n",
      "processing edge_3_7.54_2 for training data\n",
      "processing edge_3_7.54_3 for training data\n",
      "processing edge_3_7.54_4 for training data\n",
      "processing edge_3_7.54_5 for training data\n",
      "processing edge_3_7.54_6 for training data\n",
      "processing edge_3_7.54_7 for training data\n",
      "processing edge_3_7.54_8 for training data\n",
      "processing edge_3_7.54_9 for training data\n",
      "processing edge_3_7.54_10 for training data\n",
      "processing edge_3_7.54_11 for training data\n",
      "processing edge_3_7.54_12 for training data\n",
      "processing edge_3_7.54_13 for training data\n",
      "processing edge_3_7.54_14 for training data\n",
      "processing edge_3_7.54_15 for training data\n",
      "processing edge_3_7.54_16 for training data\n",
      "processing edge_3_7.54_17 for training data\n",
      "processing edge_3_7.47_0 for training data\n",
      "processing edge_3_7.47_1 for training data\n",
      "processing edge_3_7.47_2 for training data\n",
      "processing edge_3_7.47_3 for training data\n",
      "processing edge_3_7.47_4 for training data\n",
      "processing edge_3_7.47_5 for training data\n",
      "processing edge_3_7.47_6 for training data\n",
      "processing edge_3_7.47_7 for training data\n",
      "processing edge_3_7.47_8 for training data\n",
      "processing edge_3_7.47_9 for training data\n",
      "processing edge_3_7.47_10 for training data\n",
      "processing edge_3_7.47_11 for training data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing edge_3_7.47_12 for training data\n",
      "processing edge_3_7.47_13 for training data\n",
      "processing edge_3_7.47_14 for training data\n",
      "processing edge_3_7.47_15 for training data\n",
      "processing edge_3_7.47_16 for training data\n",
      "processing edge_3_7.47_17 for training data\n",
      "processing edge_3_7.41_0 for training data\n",
      "processing edge_3_7.41_1 for training data\n",
      "processing edge_3_7.41_2 for training data\n",
      "processing edge_3_7.41_3 for training data\n",
      "processing edge_3_7.41_4 for training data\n",
      "processing edge_3_7.41_5 for training data\n",
      "processing edge_3_7.41_6 for training data\n",
      "processing edge_3_7.41_7 for training data\n",
      "processing edge_3_7.41_8 for training data\n",
      "processing edge_3_7.41_9 for training data\n",
      "processing edge_3_7.41_10 for training data\n",
      "processing edge_3_7.41_11 for training data\n",
      "processing edge_3_7.41_12 for training data\n",
      "processing edge_3_7.41_13 for training data\n",
      "processing edge_3_7.41_14 for training data\n",
      "processing edge_3_7.41_15 for training data\n",
      "processing edge_3_7.41_16 for training data\n",
      "processing edge_3_7.41_17 for training data\n",
      "processing edge_3_7.35_0 for training data\n",
      "processing edge_3_7.35_1 for training data\n",
      "processing edge_3_7.35_2 for training data\n",
      "processing edge_3_7.35_3 for training data\n",
      "processing edge_3_7.35_4 for training data\n",
      "processing edge_3_7.35_5 for training data\n",
      "processing edge_3_7.35_6 for training data\n",
      "processing edge_3_7.35_7 for training data\n",
      "processing edge_3_7.35_8 for training data\n",
      "processing edge_3_7.35_9 for training data\n",
      "processing edge_3_7.35_10 for training data\n",
      "processing edge_3_7.35_11 for training data\n",
      "processing edge_3_7.35_12 for training data\n",
      "processing edge_3_7.35_13 for training data\n",
      "processing edge_3_7.35_14 for training data\n",
      "processing edge_3_7.35_15 for training data\n",
      "processing edge_3_7.35_16 for training data\n",
      "processing edge_3_7.35_17 for training data\n",
      "processing edge_3_7.28_0 for training data\n",
      "processing edge_3_7.28_1 for training data\n",
      "processing edge_3_7.28_2 for training data\n",
      "processing edge_3_7.28_3 for training data\n",
      "processing edge_3_7.28_4 for training data\n",
      "processing edge_3_7.28_5 for training data\n",
      "processing edge_3_7.28_6 for training data\n",
      "processing edge_3_7.28_7 for training data\n",
      "processing edge_3_7.28_8 for training data\n",
      "processing edge_3_7.28_9 for training data\n",
      "processing edge_3_7.28_10 for training data\n",
      "processing edge_3_7.28_11 for training data\n",
      "processing edge_3_7.28_12 for training data\n",
      "processing edge_3_7.28_13 for training data\n",
      "processing edge_3_7.28_14 for training data\n",
      "processing edge_3_7.28_15 for training data\n",
      "processing edge_3_7.28_16 for training data\n",
      "processing edge_3_7.28_17 for training data\n",
      "processing edge_3_7.22_0 for training data\n",
      "processing edge_3_7.22_1 for training data\n",
      "processing edge_3_7.22_2 for training data\n",
      "processing edge_3_7.22_3 for training data\n",
      "processing edge_3_7.22_4 for training data\n",
      "processing edge_3_7.22_5 for training data\n",
      "processing edge_3_7.22_6 for training data\n",
      "processing edge_3_7.22_7 for training data\n",
      "processing edge_3_7.22_8 for training data\n",
      "processing edge_3_7.22_9 for training data\n",
      "processing edge_3_7.22_10 for training data\n",
      "processing edge_3_7.22_11 for training data\n",
      "processing edge_3_7.22_12 for training data\n",
      "processing edge_3_7.22_13 for training data\n",
      "processing edge_3_7.22_14 for training data\n",
      "processing edge_3_7.22_15 for training data\n",
      "processing edge_3_7.22_16 for training data\n",
      "processing edge_3_7.22_17 for training data\n",
      "processing edge_3_7.17_0 for training data\n",
      "processing edge_3_7.17_1 for training data\n",
      "processing edge_3_7.17_2 for training data\n",
      "processing edge_3_7.17_3 for training data\n",
      "processing edge_3_7.17_4 for training data\n",
      "processing edge_3_7.17_5 for training data\n",
      "processing edge_3_7.17_6 for training data\n",
      "processing edge_3_7.17_7 for training data\n",
      "processing edge_3_7.17_8 for training data\n",
      "processing edge_3_7.17_9 for training data\n",
      "processing edge_3_7.17_10 for training data\n",
      "processing edge_3_7.17_11 for training data\n",
      "processing edge_3_7.17_12 for training data\n",
      "processing edge_3_7.17_13 for training data\n",
      "processing edge_3_7.17_14 for training data\n",
      "processing edge_3_7.17_15 for training data\n",
      "processing edge_3_7.17_16 for training data\n",
      "processing edge_3_7.17_17 for training data\n",
      "processing edge_3_7.11_0 for training data\n",
      "processing edge_3_7.11_1 for training data\n",
      "processing edge_3_7.11_2 for training data\n",
      "processing edge_3_7.11_3 for training data\n",
      "processing edge_3_7.11_4 for training data\n",
      "processing edge_3_7.11_5 for training data\n",
      "processing edge_3_7.11_6 for training data\n",
      "processing edge_3_7.11_7 for training data\n",
      "processing edge_3_7.11_8 for training data\n",
      "processing edge_3_7.11_9 for training data\n",
      "processing edge_3_7.11_10 for training data\n",
      "processing edge_3_7.11_11 for training data\n",
      "processing edge_3_7.11_12 for training data\n",
      "processing edge_3_7.11_13 for training data\n",
      "processing edge_3_7.11_14 for training data\n",
      "processing edge_3_7.11_15 for training data\n",
      "processing edge_3_7.11_16 for training data\n",
      "processing edge_3_7.11_17 for training data\n",
      "processing edge_3_7.06_0 for training data\n",
      "processing edge_3_7.06_1 for training data\n",
      "processing edge_3_7.06_2 for training data\n",
      "processing edge_3_7.06_3 for training data\n",
      "processing edge_3_7.06_4 for training data\n",
      "processing edge_3_7.06_5 for training data\n",
      "processing edge_3_7.06_6 for training data\n",
      "processing edge_3_7.06_7 for training data\n",
      "processing edge_3_7.06_8 for training data\n",
      "processing edge_3_7.06_9 for training data\n",
      "processing edge_3_7.06_10 for training data\n",
      "processing edge_3_7.06_11 for training data\n",
      "processing edge_3_7.06_12 for training data\n",
      "processing edge_3_7.06_13 for training data\n",
      "processing edge_3_7.06_14 for training data\n",
      "processing edge_3_7.06_15 for training data\n",
      "processing edge_3_7.06_16 for training data\n",
      "processing edge_3_7.06_17 for training data\n",
      "processing edge_3_7.00_0 for training data\n",
      "processing edge_3_7.00_1 for training data\n",
      "processing edge_3_7.00_2 for training data\n",
      "processing edge_3_7.00_3 for training data\n",
      "processing edge_3_7.00_4 for training data\n",
      "processing edge_3_7.00_5 for training data\n",
      "processing edge_3_7.00_6 for training data\n",
      "processing edge_3_7.00_7 for training data\n",
      "processing edge_3_7.00_8 for training data\n",
      "processing edge_3_7.00_9 for training data\n",
      "processing edge_3_7.00_10 for training data\n",
      "processing edge_3_7.00_11 for training data\n",
      "processing edge_3_7.00_12 for training data\n",
      "processing edge_3_7.00_13 for training data\n",
      "processing edge_3_7.00_14 for training data\n",
      "processing edge_3_7.00_15 for training data\n",
      "processing edge_3_7.00_16 for training data\n",
      "processing edge_3_7.00_17 for training data\n",
      "Done processing unlbl files\n",
      "elapsed time: 3196.541982\n"
     ]
    }
   ],
   "source": [
    "processUnlbl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@time_usage\n",
    "def processUnlbl(noise=0.):\n",
    "    nlimPerFile = 270+nblSkip\n",
    "    for run in unlblnames:\n",
    "        fnames = [run+\"_\"+str(i) for i in uidx]\n",
    "        fout = open(unlabeled_dir+run+noiseappend,'w') #erases file\n",
    "        fout.close()\n",
    "        for f in fnames:\n",
    "            fin = open(in_dir+f,'r')\n",
    "            print \"processing \" + f + noiseappend + \" for training data\"\n",
    "            fout = open(unlabeled_dir+run+noiseappend,'a')\n",
    "\n",
    "            # find width from file header\n",
    "            width, height = 0., 0.\n",
    "            l = fin.readline().split(\"|\")\n",
    "            for ll in l:\n",
    "                if \"boxEdge\" in ll:\n",
    "                    width = float(ll.split()[1])\n",
    "            height = width\n",
    "            fin.seek(0)\n",
    "\n",
    "            if width == 0.:\n",
    "                # calculate edge length based on vertices of first block\n",
    "                block = []\n",
    "                for line in fin.readlines():\n",
    "                    if line == \"\\n\": break\n",
    "                    if line[0].isalpha(): continue\n",
    "                    block.append(line)\n",
    "                fin.seek(0)\n",
    "                width, height = edgeLenCalc(block)\n",
    "\n",
    "            if not (fin.readline()[0].isalpha()): fin.seek(0)\n",
    "\n",
    "            thNorm = oneOver2Pi\n",
    "            normX, normY = 1./width, 1./height # normalize x and y\n",
    "\n",
    "            nbl = 0\n",
    "            fRot = 0. # rotation factor: 0,1,2,3. Multiplied by pi/2\n",
    "            block = []\n",
    "            for line in fin.readlines():\n",
    "                if line == \"\\n\":\n",
    "                    if nbl < nblSkip:\n",
    "                        nbl+=1\n",
    "                        block = []\n",
    "                        continue\n",
    "                    fRot = random.randint(0,3)\n",
    "                    for l in block:\n",
    "                        fout.write('%f %f %f\\n' % (l[0], l[1], l[2]))\n",
    "                    fout.write('\\n')\n",
    "                    block = []\n",
    "                    nbl+=1\n",
    "                    if nbl == nlimPerFile:\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                rndxy = [0.,0.]\n",
    "                rndth = 0.\n",
    "                if noise > 0.:\n",
    "                    # Gen three random numbers\n",
    "                    rndxy = np.random.normal(0,noise,2)\n",
    "                    rndth = np.random.normal(0,twopi*thnoise,1)\n",
    "    #                 rndxy = [0.,0.]\n",
    "    #                 rndth = 0.\n",
    "\n",
    "                spt = [float(x) for x in line.split()]\n",
    "                x,y,th = spt[2],spt[3],spt[4]\n",
    "                # Rotate block\n",
    "                # note thetas should be [0,2pi] initially\n",
    "                th_ = fRot*twopi*0.25\n",
    "                th += th_ + rndth\n",
    "                if th > twopi: th-=twopi\n",
    "                th *= thNorm\n",
    "\n",
    "                x = np.cos(th_)*spt[2] - np.sin(th_)*spt[3] + rndxy[0]\n",
    "                y = np.sin(th_)*spt[2] + np.cos(th_)*spt[3] + rndxy[1]\n",
    "                # shift and normalize\n",
    "                x *= normX\n",
    "                y *= normY\n",
    "\n",
    "                block.append([x,y,th])\n",
    "\n",
    "            fout.close()\n",
    "            fin.close()\n",
    "    print \"Done processing unlbl files\" "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
