{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_lbl(filename_queue, batchSize):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "    features = tf.parse_single_example(\n",
    "      serialized_example,\n",
    "      # Defaults are not specified since both keys are required.\n",
    "      features={\n",
    "        'height': tf.FixedLenFeature([], tf.int64),\n",
    "        'width': tf.FixedLenFeature([], tf.int64),\n",
    "        'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "        'label': tf.FixedLenFeature([], tf.int64)\n",
    "        })\n",
    "\n",
    "    # Convert from a scalar string tensor (whose single string has\n",
    "    # length mnist.IMAGE4_PIXELS) to a uint8 tensor with shape\n",
    "    # [mnist.IMAGE_PIXELS].\n",
    "    image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "    height = tf.cast(features['height'], tf.int32)\n",
    "    width = tf.cast(features['width'], tf.int32)\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    \n",
    "    image_shape = tf.stack([height, width, 4])\n",
    "    image = tf.reshape(image, image_shape)\n",
    "    image_size_const = tf.constant((constHeight, constWidth, 4), dtype=tf.int32)\n",
    "    \n",
    "    # Random transformations can be put here: right before you crop images\n",
    "    # to predefined size. To get more information look at the stackoverflow\n",
    "    # question linked above.\n",
    "    \n",
    "    resized_image = tf.image.resize_image_with_crop_or_pad(image=image,\n",
    "                                           target_height=constHeight,\n",
    "                                           target_width=constWidth)\n",
    "    blankvec = tf.Variable([0,0,0,0,0,0])    \n",
    "    \n",
    "    return resized_image, label, blankvec\n",
    "\n",
    "def LblBatch(filename_queue, batchSize):\n",
    "    prepped_example = read_lbl(filename_queue, batchSize)\n",
    "# trnbatch = tf.train.shuffle_batch_join(trnQlist,\n",
    "#                                         batch_size=BATCHSIZE,\n",
    "#                                         capacity=1000+3*BATCHSIZE,\n",
    "#                                         min_after_dequeue=1000)\n",
    "    imagebatch, labelbatch, blankvecs = tf.train.shuffle_batch_join(\n",
    "                                          [prepped_example[0], prepped_example[1], blankvec],\n",
    "                                          batch_size=batchSize,\n",
    "                                          capacity=1000 + batchSize*3,\n",
    "                                          min_after_dequeue=1000)\n",
    "    \n",
    "    return imagebatch, labelbatch, blankvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_unlbl(filename_queue, batchSize):\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "    features = tf.parse_single_example(\n",
    "      serialized_example,\n",
    "      # Defaults are not specified since both keys are required.\n",
    "      features={\n",
    "        'height': tf.FixedLenFeature([], tf.int64),\n",
    "        'width': tf.FixedLenFeature([], tf.int64),\n",
    "        'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "        })\n",
    "\n",
    "    # Convert from a scalar string tensor (whose single string has\n",
    "    # length mnist.IMAGE_PIXELS) to a uint8 tensor with shape\n",
    "    # [mnist.IMAGE_PIXELS].\n",
    "    image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "    height = tf.cast(features['height'], tf.int32)\n",
    "    width = tf.cast(features['width'], tf.int32)\n",
    "    \n",
    "    image_shape = tf.stack([height, width, 4])\n",
    "    image = tf.reshape(image, image_shape)\n",
    "    image_size_const = tf.constant((constHeight, constWidth, 4), dtype=tf.int32)\n",
    "    \n",
    "    # Random transformations can be put here: right before you crop images\n",
    "    # to predefined size. To get more information look at the stackoverflow\n",
    "    # question linked above.\n",
    "    \n",
    "    resized_image = tf.image.resize_image_with_crop_or_pad(image=image,\n",
    "                                           target_height=constHeight,\n",
    "                                           target_width=constWidth)\n",
    "    \n",
    "    return resized_image\n",
    "\n",
    "\n",
    "def UnlblBatch(filename_queue, batchSize):\n",
    "    prepped_example = read_unlbl(filename_queue, batchSize)\n",
    "    return tf.train.shuffle_batch([prepped_example],\n",
    "                                          batch_size=batchSize,\n",
    "                                          capacity=batchSize*2,\n",
    "                                          num_threads=2,\n",
    "                                          min_after_dequeue=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STRIDE = 4\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    s = STRIDE\n",
    "    return tf.nn.conv2d(x, W, strides=[1,s,s,1], padding='SAME')\n",
    "\n",
    "def assign_labels():\n",
    "    return\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, constHeight, constWidth, 4])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 6])\n",
    "\n",
    "x_image = tf.reshape(x, [-1, constHeight, constWidth, 4])\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, 4, 32]) # [x,y,nInputChannel,nOutChannel]\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2) + b_conv2)\n",
    "\n",
    "# Dividing by STRIDE*STRIDE for each conv layer\n",
    "len_fc1 = constHeight*constWidth*64/(STRIDE*STRIDE*STRIDE*STRIDE)\n",
    "W_fc1 = weight_variable([len_fc1, 512])\n",
    "b_fc1 = bias_variable([512])\n",
    "h_conv2_flat = tf.reshape(h_conv2, [-1, len_fc1])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_conv2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([512, 6])\n",
    "b_fc2 = bias_variable([6])\n",
    "\n",
    "y = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "trn_queue = tf.train.string_input_producer(trnrecords)\n",
    "trnQlist = [read_lbl(trn_queue, BATCHSIZE) for _ in range(len(trnrecords))]\n",
    "test_queue = tf.train.string_input_producer([testrecords[0]], num_epochs=1)\n",
    "unlbl_queue = tf.train.string_input_producer([unlblrecords[0]], num_epochs=1)\n",
    "\n",
    "# Even when reading in multiple threads, share the filename\n",
    "# queue.\n",
    "BATCHSIZE = 30\n",
    "# trnbatch = LblBatch(trn_queue, BATCHSIZE)\n",
    "trnbatch = LblBatch(trnQlist, BATCHSIZE)\n",
    "# trnbatch = tf.train.shuffle_batch_join(trnQlist,\n",
    "#                                         batch_size=BATCHSIZE,\n",
    "#                                         capacity=1000+3*BATCHSIZE,\n",
    "#                                         min_after_dequeue=1000)\n",
    "# testbatch = LblBatch(test_queue, BATCHSIZE)\n",
    "# unlblbatch = UnlblBatch(unlbl_queue, BATCHSIZE)\n",
    "\n",
    "# The op for initializing the variables.\n",
    "init_op = tf.group(tf.global_variables_initializer(),\n",
    "                   tf.local_variables_initializer())\n",
    "\n",
    "print \"About to start sess\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init_op)\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    print \"Initialized sess\"\n",
    "    \n",
    "    for i in xrange(1,4):\n",
    "    \n",
    "        trnbatch_py = sess.run([trnbatch[0], trnbatch[1], trnbatch[2]])\n",
    "        testbatch_py = sess.run([testbatch[0], testbatch[1], testbatch[2]])\n",
    "        \n",
    "        print \"step\", i\n",
    "        # Assign proper labels to the lblvecs\n",
    "        # Currently lblvecs is a batch of blank (zeros) rows\n",
    "        for l in range(len(trnbatch_py[1])):\n",
    "            trnbatch_py[2][l][trnbatch_py[1][l]] = 1\n",
    "        print trnbatch_py[2]\n",
    "\n",
    "#         for p in trnbatch_py[0][0:6]:\n",
    "#             io.imshow(p)\n",
    "#             io.show()\n",
    "\n",
    "        if i % 2 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "                x: trnbatch_py[0], y_: trnbatch_py[2], keep_prob: 1.0})\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "        train_step.run(feed_dict={x: trnbatch_py[0], y_: trnbatch_py[2], keep_prob: 0.5})\n",
    "\n",
    "#         print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "#             x: images, y_: lblvecs, keep_prob: 1.0}))\n",
    "        \n",
    "    print \"Closing sess\"\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
