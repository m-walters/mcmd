{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%source bin/activate\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import skimage.io as io\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT, IMG_WIDTH = 128, 128\n",
    "\n",
    "# labels -- [iso, D, T, X, U, L]\n",
    "NLBL = 2\n",
    "\n",
    "rundir = \"/home/walterms/project/walterms/mcmd/nn/cnn/data/mixed/\"\n",
    "trndir = rundir+\"train/\"\n",
    "testdir = rundir+\"test/\"\n",
    "unlbldir = rundir+\"unlbl/\"\n",
    "\n",
    "trnsubset = [\"edge15.tfrecords\", \"edge40.tfrecords\"]\n",
    "testsubset = [\"edge15.tfrecords\", \"edge40.tfrecords\"]\n",
    "unlblsubset = [\"\"]\n",
    "\n",
    "testrecords, unlblrecords, trnrecords = [],[],[]\n",
    "\n",
    "if trnsubset == [\"\"]:\n",
    "    trnrecords = [trndir+x for x in os.listdir(trndir)]\n",
    "else:\n",
    "    trnrecords = [trndir+x for x in trnsubset]\n",
    "if testsubset == [\"\"]:\n",
    "    testrecords = [testdir+x for x in os.listdir(testdir)]\n",
    "else:\n",
    "    testrecords = [testdir+x for x in testsubset]\n",
    "if unlblsubset == [\"\"]:\n",
    "    unlblrecords = [unlbldir+x for x in os.listdir(unlbldir)]\n",
    "else:\n",
    "    unlblrecords = [unlbldir+x for x in unlblsubset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/edgevar/train/edge15.tfrecords\n"
     ]
    }
   ],
   "source": [
    "print \"./data/edgevar/train/edge15.tfrecords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/walterms/project/walterms/mcmd/nn/cnn/data/mixed/train/edge15.tfrecords', '/home/walterms/project/walterms/mcmd/nn/cnn/data/mixed/train/edge40.tfrecords'] ['/home/walterms/project/walterms/mcmd/nn/cnn/data/mixed/test/edge15.tfrecords', '/home/walterms/project/walterms/mcmd/nn/cnn/data/mixed/test/edge40.tfrecords']\n"
     ]
    }
   ],
   "source": [
    "print trnrecords, testrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchrecord = [\"/home/walterms/project/walterms/mcmd/nn/cnn/data/benchmark/benchmark.tfrecords\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_records(filename_queue, batchSize, labeled):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    \n",
    "    features = None\n",
    "    if labeled == True:\n",
    "        features = tf.parse_single_example(\n",
    "          serialized_example,\n",
    "          # Defaults are not specified since both keys are required.\n",
    "          features={\n",
    "            'height': tf.FixedLenFeature([], tf.int64),\n",
    "            'width': tf.FixedLenFeature([], tf.int64),\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "            })\n",
    "    elif labeled == False:\n",
    "        features = tf.parse_single_example(\n",
    "          serialized_example,\n",
    "          # Defaults are not specified since both keys are required.\n",
    "          features={\n",
    "            'height': tf.FixedLenFeature([], tf.int64),\n",
    "            'width': tf.FixedLenFeature([], tf.int64),\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string)\n",
    "            })\n",
    "    else:\n",
    "        print \"Need to specify record type (labeled or not) for read_records\"\n",
    "        return\n",
    "\n",
    "    # Convert from a scalar string tensor (whose single string has\n",
    "    # length mnist.IMAGE_PIXELS) to a uint8 tensor with shape\n",
    "    # [mnist.IMAGE_PIXELS].\n",
    "    image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "#     height = tf.cast(features['height'], tf.int32)\n",
    "#     width = tf.cast(features['width'], tf.int32)\n",
    "    \n",
    "    label = None\n",
    "    blankvec = None\n",
    "    if labeled == True:\n",
    "        label = tf.cast(features['label'], tf.int32)\n",
    "        v = [0 for i in range(NLBL)]\n",
    "        blankvec = tf.Variable(v)    \n",
    "    \n",
    "    image_shape = tf.stack([IMG_HEIGHT,IMG_WIDTH])\n",
    "    image_reshaped = tf.reshape(image, image_shape)\n",
    "#     image_size_const = tf.constant((IMG_HEIGHT, IMG_WIDTH), dtype=tf.int32)\n",
    "    \n",
    "#     # Random transformations can be put here: right before you crop images\n",
    "#     # to predefined size. To get more information look at the stackoverflow\n",
    "#     # question linked above.\n",
    "    \n",
    "#     resized_image = tf.image.resize_image_with_crop_or_pad(image=image,\n",
    "#                                            target_height=constHeight,\n",
    "#                                            target_width=constWidth)\n",
    "    \n",
    "    if labeled == True:\n",
    "        return image_reshaped, label, blankvec\n",
    "    else:\n",
    "        return image_reshaped\n",
    "\n",
    "def shuffled_queue_join(Qlist, batchSize):\n",
    "    return tf.train.shuffle_batch_join(Qlist,\n",
    "                                        batch_size=batchSize,\n",
    "                                        capacity=1000+3*batchSize,\n",
    "                                        min_after_dequeue=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to start sess\n",
      "Initialized sess\n",
      "step 24, training accuracy (sample) 0.52, test accuracy 0.475\n",
      "Test Label Sums: [105, 95]\n",
      "step 49, training accuracy (sample) 0.59, test accuracy 0.475\n",
      "Test Label Sums: [94, 106]\n",
      "step 74, training accuracy (sample) 0.67, test accuracy 0.59\n",
      "Test Label Sums: [111, 89]\n",
      "step 99, training accuracy (sample) 0.39, test accuracy 0.58\n",
      "Test Label Sums: [116, 84]\n",
      "step 124, training accuracy (sample) 0.44, test accuracy 0.52\n",
      "Test Label Sums: [104, 96]\n",
      "step 149, training accuracy (sample) 0.48, test accuracy 0.53\n",
      "Test Label Sums: [106, 94]\n",
      "step 174, training accuracy (sample) 0.42, test accuracy 0.545\n",
      "Test Label Sums: [109, 91]\n",
      "step 199, training accuracy (sample) 0.07, test accuracy 0.59\n",
      "Test Label Sums: [118, 82]\n",
      "step 224, training accuracy (sample) 0.99, test accuracy 0.435\n",
      "Test Label Sums: [113, 87]\n",
      "step 249, training accuracy (sample) 1, test accuracy 0.375\n",
      "Test Label Sums: [125, 75]\n",
      "step 274, training accuracy (sample) 1, test accuracy 0.415\n",
      "Test Label Sums: [117, 83]\n",
      ">> elapsed time: 60.014084 seconds\n",
      "step 299, training accuracy (sample) 1, test accuracy 0.43\n",
      "Test Label Sums: [114, 86]\n",
      "step 324, training accuracy (sample) 1, test accuracy 0.455\n",
      "Test Label Sums: [109, 91]\n",
      "step 349, training accuracy (sample) 1, test accuracy 0.44\n",
      "Test Label Sums: [112, 88]\n",
      "step 374, training accuracy (sample) 1, test accuracy 0.49\n",
      "Test Label Sums: [102, 98]\n",
      "step 399, training accuracy (sample) 0.67, test accuracy 0.53\n",
      "Test Label Sums: [94, 106]\n",
      "step 424, training accuracy (sample) 0.56, test accuracy 0.505\n",
      "Test Label Sums: [99, 101]\n",
      "step 449, training accuracy (sample) 0.54, test accuracy 0.51\n",
      "Test Label Sums: [98, 102]\n",
      "step 474, training accuracy (sample) 0.48, test accuracy 0.48\n",
      "Test Label Sums: [104, 96]\n",
      "step 499, training accuracy (sample) 0.51, test accuracy 0.48\n",
      "Test Label Sums: [104, 96]\n",
      "Closing sess\n"
     ]
    }
   ],
   "source": [
    "# Divide by stride*stride for each conv layer\n",
    "filterWidth = 15\n",
    "stride = 8\n",
    "conv1_nOut = 32\n",
    "conv2_nOut = 64\n",
    "fc1_nIn = IMG_HEIGHT*IMG_WIDTH*conv2_nOut/(stride*stride*stride*stride)\n",
    "fc1_nOut = 512\n",
    "\n",
    "trnBatchSize = 100\n",
    "testSetSize = 200\n",
    "eta = 1e-4\n",
    "nTrnIter = 500\n",
    "testStep = nTrnIter/20\n",
    "\n",
    "beta = 1e-3\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    s = stride\n",
    "    return tf.nn.conv2d(x, W, strides=[1,s,s,1], padding='SAME')\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, IMG_HEIGHT, IMG_WIDTH])\n",
    "x_norm = tf.scalar_mul(1./255.,x)\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, NLBL])\n",
    "\n",
    "x_image = tf.reshape(x_norm, [-1, IMG_HEIGHT, IMG_WIDTH, 1])\n",
    "\n",
    "W_conv1 = weight_variable([filterWidth, filterWidth, 1, conv1_nOut]) # [x,y,nInputChannel,nOutChannel]\n",
    "b_conv1 = bias_variable([conv1_nOut])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([filterWidth, filterWidth, conv1_nOut, conv2_nOut])\n",
    "b_conv2 = bias_variable([conv2_nOut])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2) + b_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([fc1_nIn, fc1_nOut])\n",
    "b_fc1 = bias_variable([fc1_nOut])\n",
    "h_conv2_flat = tf.reshape(h_conv2, [-1, fc1_nIn])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_conv2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([fc1_nOut, NLBL])\n",
    "b_fc2 = bias_variable([NLBL])\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "regularizers = tf.nn.l2_loss(W_fc2) + tf.nn.l2_loss(W_fc1)\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "loss = tf.reduce_mean(cross_entropy + beta * regularizers)\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(eta).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# the Qlist is needed for shuffling\n",
    "trn_queue = tf.train.string_input_producer(trnrecords)\n",
    "trnQlist = [read_records(trn_queue, trnBatchSize, labeled=True) \n",
    "            for _ in range(len(trnrecords))]\n",
    "# Even when reading in multiple threads, share the filename queue\n",
    "trnbatch = shuffled_queue_join(trnQlist, trnBatchSize)\n",
    "\n",
    "# make a Qlist for test in case we only want\n",
    "# to test a subset\n",
    "test_queue = tf.train.string_input_producer(testrecords)\n",
    "testQlist = [read_records(test_queue, testSetSize, labeled=True) \n",
    "             for _ in range(len(testrecords))]\n",
    "testbatch = shuffled_queue_join(testQlist, testSetSize)\n",
    "\n",
    "unlbl_queue = tf.train.string_input_producer([unlblrecords[0]], num_epochs=1)\n",
    "\n",
    "# bench_queue = tf.train.string_input_producer(benchrecord, num_epochs=1)\n",
    "# benchQlist = [read_records(bench_queue, 9, labeled=True)]\n",
    "# benchbatch = shuffled_queue_join(benchQlist, 9)\n",
    "# # benchbatch = tf.train.shuffle_batch_join(Qlist,\n",
    "# #                                         batch_size=batchSize,\n",
    "# #                                         capacity=1000+3*batchSize,\n",
    "# #                                         min_after_dequeue=1000)\n",
    "\n",
    "# The op for initializing the variables.\n",
    "init_op = tf.group(tf.global_variables_initializer(),\n",
    "                   tf.local_variables_initializer())\n",
    "\n",
    "print \"About to start sess\"\n",
    "beg_ts = time.time()\n",
    "chkpt_ts = time.time()\n",
    "\n",
    "yTestOuts = []\n",
    "yTestLbls = []\n",
    "benchResults = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init_op)\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    print \"Initialized sess\"\n",
    "    \n",
    "    for i in xrange(0,nTrnIter):\n",
    "    \n",
    "#         trnbatch_py = sess.run([trnbatch])\n",
    "        trnbatch_py = sess.run([trnbatch[0], trnbatch[1], trnbatch[2]])\n",
    "        \n",
    "        # Assign proper labels to the lblvecs\n",
    "        # Currently lblvecs is a batch of blank (zeros) rows\n",
    "        # labels -- [iso, D, T, X, U, L]\n",
    "        for l in range(trnBatchSize):\n",
    "            trnbatch_py[2][l][trnbatch_py[1][l]] = 1\n",
    "\n",
    "        train_step.run(feed_dict={x: trnbatch_py[0], y_: trnbatch_py[2], keep_prob: 0.5})\n",
    "        \n",
    "#         print trnbatch_py[2][0:4]\n",
    "#         for p in trnbatch_py[0][0:4]:\n",
    "#             io.imshow(p)\n",
    "#             io.show()\n",
    "        now = time.time()\n",
    "        if (now-chkpt_ts) > 60:\n",
    "            print(\">> elapsed time: %f seconds\" % (now - beg_ts))\n",
    "            chkpt_ts = now\n",
    "        if (i+1) % testStep == 0:\n",
    "            trn_accuracy = accuracy.eval(feed_dict={\n",
    "                x: trnbatch_py[0], y_: trnbatch_py[2], keep_prob: 1.0})\n",
    "\n",
    "#             testbatch_py = sess.run([testbatch])\n",
    "            testbatch_py = sess.run([testbatch[0], testbatch[1], testbatch[2]])\n",
    "            \n",
    "            testLblSums = [0 for b in range(NLBL)]\n",
    "            for l in range(testSetSize):\n",
    "                testbatch_py[2][l][testbatch_py[1][l]] = 1\n",
    "                testLblSums[testbatch_py[1][l]] += 1\n",
    "\n",
    "            y_py, test_accuracy = sess.run([y, accuracy], \n",
    "                                    feed_dict={x:testbatch_py[0], y_:testbatch_py[2], keep_prob:1.0})\n",
    "            yTestOuts.append(y_py)\n",
    "            yTestLbls.append(testbatch_py[1])\n",
    "            print('step %d, training accuracy (sample) %g, test accuracy %g' \n",
    "                  % (i, trn_accuracy, test_accuracy))\n",
    "            print \"Test Label Sums:\", testLblSums\n",
    "        \n",
    "    \n",
    "#     # Run on benchmark images\n",
    "#     benchbatch_py = sess.run([benchbatch[0], benchbatch[1], benchbatch[2]])\n",
    "#     for l in range(9):\n",
    "#         benchbatch_py[2][l][benchbatch_py[1][l]] = 1\n",
    "\n",
    "#     y_py, bench_accuracy = sess.run([y, accuracy], \n",
    "#                             feed_dict={x:benchbatch_py[0], y_:benchbatch_py[2], keep_prob:1.0})\n",
    "\n",
    "#     for b in range(len(y_py)):\n",
    "#         benchResults.append([benchbatch_py[0][b],\n",
    "#                              y_py[b],\n",
    "#                              benchbatch_py[1][b]])\n",
    "    \n",
    "    print \"Closing sess\"\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# labels -- [iso, D, T, X, U, L]\n",
    "for b in benchResults:\n",
    "    print b[1],b[2]\n",
    "    io.imshow(b[0])\n",
    "    io.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAEKCAYAAAA4ga4lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiQ1xwRFkiQ1xwRFkiQ15/8DyFnVray318IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b794323aed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = []\n",
    "lbls = []\n",
    "img = 4\n",
    "\n",
    "for i in range(len(yTestOuts)):\n",
    "    o = yTestOuts[i][img]\n",
    "#     minn = np.min(o)\n",
    "#     o = o-minn\n",
    "#     maxx = np.max(o)\n",
    "#     o = o/maxx\n",
    "    p.append(o)\n",
    "    lbls.append([0 for _ in range(NLBL)])\n",
    "    lbls[-1][yTestLbls[i][img]] = 1\n",
    "\n",
    "pp = np.asarray(p).transpose()\n",
    "plbls = np.asarray(lbls).transpose()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(9, 4.8))\n",
    "# for ax in axes.flat:\n",
    "#     im = ax.imshow(np.random.random((10,10)), vmin=0, vmax=1)\n",
    "im = ax[0].imshow(plbls)\n",
    "im = ax[1].imshow(pp, vmin=np.min(pp), vmax=np.max(pp))\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edge40', 'edge35', 'edge30.0', 'edge29.2', 'edge28.6', 'edge27.9', 'edge27.4', 'edge26.8', 'edge26.3', 'edge25.8', 'edge25.4', 'edge24.9', 'edge24.5', 'edge24.1', 'edge23.7', 'edge23.4', 'edge23.0', 'edge22.7', 'edge22.4', 'edge22.1', 'edge21.8', 'edge21.5', 'edge21.2', 'edge21.0', 'edge20.7', 'edge20.5', 'edge20.2', 'edge20.0', 'edge19.8', 'edge19.6', 'edge19.4', 'edge19.2', 'edge18.9', 'edge18.5', 'edge18', 'edge17.5', 'edge17', 'edge16.75', 'edge16.5', 'edge16.25', 'edge16', 'edge15.75', 'edge15.5', 'edge15.25', 'edge15']\n"
     ]
    }
   ],
   "source": [
    "edges = []\n",
    "edgefile = open(\"../edgelist\",\"r\")\n",
    "for e in edgefile.readlines():\n",
    "    edges.append(e.strip())\n",
    "\n",
    "N = 400\n",
    "L = 3.0\n",
    "rho_ = [L*L*N/(float(x)*float(x)) for x in edges]\n",
    "\n",
    "unlabeledfnames = [\"edge\"+str(x) for x in edges]\n",
    "print unlabeledfnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
